{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wildemberg-Projects/Plants-Diseases/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO0dwdyQ-M_O"
      },
      "outputs": [],
      "source": [
        "# Instalação de Dependências\n",
        "# Para utilização do Colab, modifique o '%' por '!'\n",
        "# As abaixo comentadas são somente para instalar em ambiente local\n",
        "# %pip install -q -U tensorflow\n",
        "# %pip install -q -U keras\n",
        "# %pip install -q -U numpy\n",
        "# %pip install -q -U pandas\n",
        "# %pip install -q -U Jinja2\n",
        "# Uso da GPU precisa ser habilitado pelo comando a seguir\n",
        "# %pip install tensorflow[and-cuda]\n",
        "%pip install -q -U tensorflow-addons\n",
        "%pip install -q -U tensorflow-datasets\n",
        "%pip install -q -U keras-utils\n",
        "%pip install -q -U matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oOBTtaKjCVkm"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CNowqre2CWz0"
      },
      "outputs": [],
      "source": [
        "# Coletando dados\n",
        "tf.keras.backend.clear_session()\n",
        "(ds_train), info = tfds.load('plant_village', split='train', with_info=True)\n",
        "N_classes_total = 38\n",
        "\n",
        "# a estrutura de uma imagem (256,256,3), representa a largura e altura em pixels,\n",
        "# e o 3 representa a quantidade de canais de cores pq é RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_D4MKxY61az"
      },
      "outputs": [],
      "source": [
        "# Visualização da Distribuição das Classes\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='label', data=df_train)\n",
        "plt.title('Distribuição das Labels')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Número de Exemplos')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função que será responsável por aplicar um tratamento dos dados para conversão de tipo\n",
        "def processamento(val):\n",
        "  image = val['image']\n",
        "  label = val['label']\n",
        "  # normalização das imagens convertendo para um tipo que melhor é processado e para um intervalo entre [0, 1]\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  return image, label\n"
      ],
      "metadata": {
        "id": "3tDSBzuBrUe4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCRPJIJopU9b",
        "outputId": "945f92e7-4cb8-48d0-8905-93729d76ef54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'image': array([[[171, 161, 169],\n",
              "          [158, 148, 156],\n",
              "          [153, 143, 151],\n",
              "          ...,\n",
              "          [144, 133, 137],\n",
              "          [130, 119, 123],\n",
              "          [151, 140, 144]],\n",
              "  \n",
              "         [[164, 154, 162],\n",
              "          [158, 148, 156],\n",
              "          [161, 151, 159],\n",
              "          ...,\n",
              "          [131, 120, 124],\n",
              "          [ 86,  75,  79],\n",
              "          [104,  93,  97]],\n",
              "  \n",
              "         [[150, 140, 148],\n",
              "          [155, 145, 153],\n",
              "          [161, 151, 159],\n",
              "          ...,\n",
              "          [101,  90,  94],\n",
              "          [ 90,  79,  83],\n",
              "          [124, 113, 117]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[176, 165, 169],\n",
              "          [160, 149, 153],\n",
              "          [163, 152, 156],\n",
              "          ...,\n",
              "          [158, 146, 146],\n",
              "          [137, 125, 125],\n",
              "          [112, 100, 100]],\n",
              "  \n",
              "         [[171, 160, 164],\n",
              "          [190, 179, 183],\n",
              "          [151, 140, 144],\n",
              "          ...,\n",
              "          [149, 137, 137],\n",
              "          [140, 128, 128],\n",
              "          [105,  93,  93]],\n",
              "  \n",
              "         [[142, 131, 135],\n",
              "          [182, 171, 175],\n",
              "          [173, 162, 166],\n",
              "          ...,\n",
              "          [141, 129, 129],\n",
              "          [157, 145, 145],\n",
              "          [134, 122, 122]]], dtype=uint8),\n",
              "  'image/filename': b'image (785).JPG',\n",
              "  'label': 35}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Filtrar dataframe para somente tomate\n",
        "N_classes_tomate = 11\n",
        "def filtrar_tomates(exemplo):\n",
        "    return exemplo[\"label\"] > 27  # Supondo que \"label\" seja a chave que contém as labels\n",
        "\n",
        "# Aplicando a função de filtro ao dataset\n",
        "filtered_tomato = ds_train.filter(filtrar_tomates)\n",
        "list(filtered_tomato.take(1).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo normalização e processamento para as de tomate\n",
        "ds_tomate = filtered_tomato.map(processamento)\n",
        "\n",
        "# Fazendo divisão da base de dados do tomate\n",
        "ds_tomate = ds_tomate.shuffle(1000).prefetch(1)\n",
        "\n",
        "# Calcular o tamanho do conjunto de validação como 25% dos dados de treinamento\n",
        "train_size = ds_tomate.cardinality().numpy()\n",
        "validation_size = train_size // 4  # 25% dos dados de treinamento\n",
        "\n",
        "# Dividindo os dados\n",
        "ds_tomate_validation = ds_tomate.take(validation_size)\n",
        "ds_tomate_train = ds_tomate.skip(validation_size)\n",
        "\n",
        "# for image, label in ds_tomate_validation.take(1):\n",
        "#     print(\"Imagem de treinamento após o processamento: \\n{} \\ne label {}\".format(image.shape, label))\n",
        "\n",
        "ds_tomate_validation_x = ds_tomate_validation.map(lambda img, lbl: img)\n",
        "ds_tomate_validation_y = ds_tomate_validation.map(lambda img, lbl: lbl)\n",
        "\n",
        "ds_tomate_train_x = ds_tomate_train.map(lambda img, lbl: img)\n",
        "ds_tomate_train_y = ds_tomate_train.map(lambda img, lbl: lbl)\n"
      ],
      "metadata": {
        "id": "QmQG2np6sAKA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yxA_wy7pU9b",
        "outputId": "db52db11-ae0d-4a7b-c737-eebbc3467cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.take_op._TakeDataset'>\n"
          ]
        }
      ],
      "source": [
        "# Diminuindo tamanho do dataset para melhor processamento\n",
        "\n",
        "# Embaralhando os dados para garantir que tanto a validação quanto o treinamento tenham todos os tipos de dados\n",
        "ds_train = ds_train.shuffle(buffer_size=1000, seed=42)\n",
        "filtered_dataset = ds_train.take(20000)\n",
        "list(filtered_dataset.take(1).as_numpy_iterator())\n",
        "print(type(filtered_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo normalização e processamento para os dados reduzidos\n",
        "\n",
        "filtered_dataset = filtered_dataset.map(processamento)\n",
        "\n",
        "# Fazendo divisão da base de dados do tomate\n",
        "filtered_dataset = filtered_dataset.shuffle(1000).prefetch(1)\n",
        "\n",
        "# Calcular o tamanho do conjunto de validação como 25% dos dados de treinamento\n",
        "train_size = filtered_dataset.cardinality().numpy()\n",
        "validation_size = train_size // 4  # 25% dos dados de treinamento\n",
        "\n",
        "# Dividindo os dados\n",
        "filtered_dataset_validation = filtered_dataset.take(validation_size)\n",
        "filtered_dataset_train = filtered_dataset.skip(validation_size)\n",
        "\n",
        "# for image, label in filtered_dataset_validation.take(1):\n",
        "#     print(\"Shape da imagem de treinamento após o processamento:{} e label {}\".format(image, label))\n",
        "\n",
        "filtered_dataset_validation_x = filtered_dataset_validation.map(lambda img, lbl: img)\n",
        "filtered_dataset_validation_y = filtered_dataset_validation.map(lambda img, lbl: lbl)\n",
        "\n",
        "filtered_dataset_train_x = filtered_dataset_train.map(lambda img, lbl: img)\n",
        "filtered_dataset_train_y = filtered_dataset_train.map(lambda img, lbl: lbl)\n"
      ],
      "metadata": {
        "id": "83USTEODxZrm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in filtered_dataset_train_y.take(5):\n",
        "  print(label)\n"
      ],
      "metadata": {
        "id": "amURNI8t8NR8",
        "outputId": "451397a2-c930-46ea-f12a-bdcbb3db3255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'element_spec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c4f159985749>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_dataset_train_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/as_dataframe.py\u001b[0m in \u001b[0;36mas_dataframe\u001b[0;34m(ds, ds_info)\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0;31m# Flatten the keys names, specs,... while keeping the feature key definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0;31m# order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m   \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m   \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_row_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyledDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \"\"\")\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'element_spec'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP1IfA5RCcxp",
        "outputId": "5f391ba0-d0b9-47cc-fe7d-00d2c1c02eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de exemplos de treinamento: 40728\n",
            "Número de exemplos de validação: 13575\n"
          ]
        }
      ],
      "source": [
        "# Dividir os dados de treinamento em treinamento e validação sem filtragem\n",
        "\n",
        "ds_train2 = ds_train.map(processamento)\n",
        "\n",
        "# Embaralhando os dados para garantir que tanto a validação quanto o treinamento tenham todos os tipos de dados\n",
        "ds_train2 = ds_train2.shuffle(buffer_size=1000, seed=42).prefetch(1)\n",
        "\n",
        "# Calcular o tamanho do conjunto de validação como 25% dos dados de treinamento\n",
        "train_size = ds_train2.cardinality().numpy()\n",
        "validation_size = train_size // 4  # 25% dos dados de treinamento\n",
        "\n",
        "# Dividindo os dados\n",
        "ds_validation = ds_train2.take(validation_size)\n",
        "ds_train2 = ds_train2.skip(validation_size)\n",
        "\n",
        "# Verificar o número de exemplos em cada conjunto de dados\n",
        "num_train_examples = ds_train2.cardinality().numpy()\n",
        "num_validation_examples = ds_validation.cardinality().numpy()\n",
        "print(\"Número de exemplos de treinamento:\", num_train_examples)\n",
        "print(\"Número de exemplos de validação:\", num_validation_examples)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_validation_x = ds_validation.map(lambda img, lbl: img)\n",
        "ds_validation_y = ds_validation.map(lambda img, lbl: lbl)\n",
        "\n",
        "ds_train_x = ds_train2.map(lambda img, lbl: img)\n",
        "ds_train_y = ds_train2.map(lambda img, lbl: lbl)\n"
      ],
      "metadata": {
        "id": "p5F-NVIdFmIW"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}