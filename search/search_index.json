{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>"},{"location":"#home","title":"Home","text":"Ol\u00e1, bem vindo a documenta\u00e7\u00e3o do projeto Plants-Diseases. Somos uma equipe de 5 pessoas trabalhando no projeto, iniciado na mat\u00e9ria \"Machine Learning\" na Universidade de Bras\u00edlia, com o professor S\u00e9rgio Freitas durante o semestre 2024.1"},{"location":"#o-projeto","title":"O projeto","text":"Tendo em vista a import\u00e2ncia de identificar doen\u00e7as e problemas em plantios com anteced\u00eancia, buscando minimizar os danos causados, nossa equipe embarcou no projeto \"Plant Disease\", que consiste no desenvolvimento de um modelo Machine Learning o qual realiza o processamento de imagens de folhas e plantas, a fim de identifica\u00e7\u00e3o de doen\u00e7as como ferrugem, o\u00eddio e outras, trazendo o grande benef\u00edcio do tempo para grandes e pequenos agricultores. <p>Para acessar nosso GitHub, clique aqui</p>"},{"location":"#a-equipe","title":"A equipe","text":"Caio Mesquita Vieira   Denniel Wiliam   Lais Portela  Lucas Lopes  Wildemberg Sales"},{"location":"etapas/entrega1/","title":"Defini\u00e7\u00e3o do problema e contextualiza\u00e7\u00e3o","text":""},{"location":"etapas/entrega1/#objetivo","title":"Objetivo","text":"<p>O objetivo deste mini trabalho \u00e9 estabelecer as bases para o projeto de Aprendizado de M\u00e1quina (ML) que visa desenvolver um software capaz de analisar imagens de plantas com doen\u00e7as e identificar o tipo de doen\u00e7a presente. Para isso, \u00e9 essencial definir claramente o problema a ser abordado, compreender o contexto no qual ele est\u00e1 inserido e estabelecer objetivos espec\u00edficos para a solu\u00e7\u00e3o proposta. Al\u00e9m disso, \u00e9 importante realizar uma an\u00e1lise do cen\u00e1rio atual, identificando solu\u00e7\u00f5es existentes, lacunas e poss\u00edveis melhorias. Por fim, devem ser escolhidas e justificadas as m\u00e9tricas de avalia\u00e7\u00e3o de desempenho alinhadas com os objetivos do projeto, estabelecendo um patamar m\u00ednimo de desempenho esperado para considerar o projeto bem-sucedido.</p>"},{"location":"etapas/entrega1/#cenario-atual-e-contexto","title":"Cen\u00e1rio Atual e contexto","text":"<p>A agricultura desempenha um papel fundamental na sustentabilidade alimentar global, fornecendo alimentos essenciais para a popula\u00e7\u00e3o mundial. No entanto, a sa\u00fade das plantas, fundamental para a produ\u00e7\u00e3o agr\u00edcola, est\u00e1 constantemente amea\u00e7ada por uma variedade de fatores, incluindo doen\u00e7as. Estas podem ser causadas por fungos, v\u00edrus, bact\u00e9rias, defici\u00eancias nutricionais, entre outros agentes patog\u00eanicos. Atualmente, a detec\u00e7\u00e3o e diagn\u00f3stico de doen\u00e7as em plantas s\u00e3o predominantemente realizados manualmente por agr\u00f4nomos e especialistas em agricultura. Este processo \u00e9 muitas vezes demorado, intensivo em m\u00e3o de obra e sujeito a erros humanos. Al\u00e9m disso, a capacidade dos especialistas em identificar doen\u00e7as pode variar, o que pode resultar em diagn\u00f3sticos imprecisos e tratamentos inadequados. Embora solu\u00e7\u00f5es computacionais baseadas em t\u00e9cnicas de processamento de imagens e aprendizado de m\u00e1quina tenham sido desenvolvidas para auxiliar na detec\u00e7\u00e3o de doen\u00e7as em plantas, muitas delas enfrentam desafios significativos. Essas solu\u00e7\u00f5es podem ser limitadas em termos de precis\u00e3o, velocidade de processamento e capacidade de generaliza\u00e7\u00e3o para diferentes tipos de plantas e doen\u00e7as. Isso pode resultar em diagn\u00f3sticos imprecisos ou ineficazes, prejudicando a efic\u00e1cia das medidas de controle e preven\u00e7\u00e3o. A introdu\u00e7\u00e3o de um software de Aprendizado de M\u00e1quina capaz de analisar imagens de plantas e identificar com precis\u00e3o o tipo de doen\u00e7a presente teria um impacto significativo no cen\u00e1rio atual da agricultura. Uma solu\u00e7\u00e3o eficaz e precisa permitiria uma detec\u00e7\u00e3o mais r\u00e1pida e confi\u00e1vel de doen\u00e7as em planta\u00e7\u00f5es possibilitando a implementa\u00e7\u00e3o de medidas preventivas e curativas de forma mais \u00e1gil e eficiente. Isso poderia resultar em redu\u00e7\u00e3o de perdas na produ\u00e7\u00e3o agr\u00edcola, aumento da efici\u00eancia dos sistemas de cultivo e, consequentemente, contribuir para a seguran\u00e7a alimentar global.</p>"},{"location":"etapas/entrega1/#metricas-de-avaliacao-e-desempenho","title":"M\u00e9tricas de avalia\u00e7\u00e3o e desempenho","text":"<ul> <li>Acur\u00e1cia: </li> </ul> <p>Justificativa: A acur\u00e1cia \u00e9 uma m\u00e9trica fundamental para avaliar a precis\u00e3o geral do modelo na classifica\u00e7\u00e3o das doen\u00e7as das plantas. Uma alta acur\u00e1cia indica que o modelo est\u00e1 fazendo previs\u00f5es corretas na maioria dos casos, o que \u00e9 crucial para garantir diagn\u00f3sticos precisos e confi\u00e1veis. </p> <p>Patamar M\u00ednimo de Desempenho: O patamar m\u00ednimo de acur\u00e1cia esperado para considerar o projeto bem-sucedido ser\u00e1 de 85%. Isso significa que o modelo deve ser capaz de classificar corretamente pelo menos 85% das imagens de plantascom doen\u00e7as.</p> <ul> <li>Precis\u00e3o: </li> </ul> <p>Justificativa: A precis\u00e3o \u00e9 importante para avaliar a propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de predi\u00e7\u00f5es positivas. Uma alta precis\u00e3o \u00e9 essencial para garantir que o modelo minimize os falsos positivos, evitando diagn\u00f3sticos incorretos que possam levar a tratamentos desnecess\u00e1rios ou inadequados. </p> <p>Patamar M\u00ednimo de Desempenho: O patamar m\u00ednimo de precis\u00e3o esperado ser\u00e1 de 80%. Isso significa que o modelo deve ser capaz de identificar corretamente pelo menos 80% das plantas diagnosticadas como portadoras de doen\u00e7as. - Revoca\u00e7\u00e3o: Justificativa: A revoca\u00e7\u00e3o \u00e9 importante para avaliar a propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de casos positivos reais. Uma alta revoca\u00e7\u00e3o \u00e9 crucial para garantir que o modelo minimize os falsos negativos, ou seja, que n\u00e3o deixe de identificar plantas doentes. Patamar M\u00ednimo de Desempenho: O patamar m\u00ednimo de revoca\u00e7\u00e3o esperado ser\u00e1 de 80%. Isso significa que o modelo deve ser capaz de identificar corretamente pelo menos 80% das plantas que realmente est\u00e3o doentes. </p> <ul> <li>F1-Score: </li> </ul> <p>Justificativa: O F1-Score \u00e9 uma medida que combina precis\u00e3o e revoca\u00e7\u00e3o, fornecendo uma avalia\u00e7\u00e3o geral do equil\u00edbrio entre essas duas m\u00e9tricas. Um alto F1-Score indica um bom equil\u00edbrio entre a capacidade do modelo de identificar corretamente casos positivos e negativos. </p> <p>Patamar M\u00ednimo de Desempenho: O patamar m\u00ednimo de F1-Score esperado ser\u00e1 de 0.8. Isso significa que o modelo deve alcan\u00e7ar um F1-Score de pelo menos 0.8 para considerar o projeto bem-sucedido.</p>"},{"location":"etapas/entrega2/","title":"Aquisi\u00e7\u00e3o de dados","text":""},{"location":"etapas/entrega2/#objetivo","title":"Objetivo","text":"<p>O objetivo da aquisi\u00e7\u00e3o de dados para treinamento do modelo \u00e9 reunir uma base de dados robusta e representativa de imagens de plantas com doen\u00e7as. Esses dados ser\u00e3o utilizados no desenvolvimento de um software de Aprendizado de M\u00e1quina (ML) destinado a analisar imagens e identificar o tipo de doen\u00e7a presente nas plantas. Para alcan\u00e7ar esse objetivo, \u00e9 crucial selecionar e adquirir imagens de plantas com uma variedade de doen\u00e7as e condi\u00e7\u00f5es, garantindo assim a diversidade necess\u00e1ria para o treinamento eficaz do modelo. Al\u00e9m disso, \u00e9 importante avaliar a qualidade e a integridade dos dados adquiridos, garantindo que estejam livres de problemas e representem fielmente o problema em quest\u00e3o. Ao estabelecer uma base de dados s\u00f3lida e bem fundamentada, ser\u00e1 poss\u00edvel desenvolver um modelo de ML preciso e confi\u00e1vel para a identifica\u00e7\u00e3o de doen\u00e7as em plantas.</p>"},{"location":"etapas/entrega2/#qualidade-e-documentacao-da-fonte-de-dados","title":"Qualidade e documenta\u00e7\u00e3o da fonte de dados","text":"<p>A base selecionada como principal fonte para os datasets ser\u00e1 a base PlantVillage disponibilizada publicamente pelo TensorFlow e que pode ser acessada atrav\u00e9s do link (ACESSO). Essa base consiste em 54303 imagens de folhas saud\u00e1veis e n\u00e3o saud\u00e1veis, divididas em 38 categorias por esp\u00e9cie e doen\u00e7a. Esse conjunto de dados foi disponibilizado pela pesquisa \u201cAn open access repository of images on plant health to enable the development of mobile disease diagnostics\u201d (ACESSO) em que a url do conjunto de dados prim\u00e1rio da pesquisa consta no link (ACESSO).</p> <p>Todas as imagens do banco de dados PlantVillage foram obtidas em esta\u00e7\u00f5es de pesquisa experimentais associadas \u00e0s Land Grant Universities nos EUA (Penn State, Florida State, Cornell e outras). (HUGHES, 2016).</p> <p>As imagens abrangem 14 esp\u00e9cies de culturas: Ma\u00e7\u00e3, Mirtilo, Cereja, Milho, Uva, Laranja, P\u00eassego, Piment\u00e3o, Batata, Framboesa, Soja, Ab\u00f3bora, Morango, Tomate. Cont\u00e9m imagens de 17 doen\u00e7as f\u00fangicas, 4 doen\u00e7as bacterianas, 2 doen\u00e7as causadas por fungos (oomicetos), 2 doen\u00e7as virais e 1 doen\u00e7a causada por um \u00e1caro. 12 esp\u00e9cies cultivadas tamb\u00e9m apresentam imagens de folhas saud\u00e1veis que n\u00e3o s\u00e3o visivelmente afetadas por uma doen\u00e7a. (HUGHES, 2016).</p> <p>HUGHES (2016) confirma a identidade das doen\u00e7as atrav\u00e9s de uma valida\u00e7\u00e3o feita por fitopatologistas especialistas. Esses especialistas trabalharam diretamente em campo com os dois t\u00e9cnicos que fizeram o diagn\u00f3stico. Os estados foram determinados com base em abordagens de fenotipagem padr\u00e3o usadas por fitopatologistas.</p> <p>Ser\u00e1 utilizado o conjunto de dados com 905 MB de dados, que emprega uma t\u00e9cnica chamada aumento de dados, ou em ingl\u00eas, \"data augmentation\". Essa abordagem consiste em gerar v\u00e1rias varia\u00e7\u00f5es dos dados existentes, proporcionando assim um conjunto de dados expandido para o treinamento. Os dados aumentados s\u00e3o baseados nos dados originais com algumas pequenas altera\u00e7\u00f5es. No caso de aumento de imagem, \u00e9 feita transforma\u00e7\u00f5es geom\u00e9tricas e de espa\u00e7o de cores (invers\u00e3o, redimensionamento, corte, brilho, contraste) para aumentar o tamanho e a diversidade do conjunto de treinamento. Isso permite que o modelo encontre uma gama mais ampla de caracter\u00edsticas e padr\u00f5es durante o processo de aprendizado.</p>"},{"location":"etapas/entrega2/#preparacao-do-ambiente-de-trabalho","title":"Prepara\u00e7\u00e3o do ambiente de trabalho","text":"<p>Para a execu\u00e7\u00e3o do projeto com as bases de datasets definidas, a equipe optou pela utiliza\u00e7\u00e3o de duas plataformas: o GitHub, para armazenamento de arquivos e controle de vers\u00e3o, e o Google Colab, para o ambiente de trabalho e treinamento do modelo. A escolha do Colab deve-se \u00e0 necessidade de alto custo de processamento de dados para treinar e validar o modelo. Assim, o Colab, oferecendo um sistema com 12.7 GB de mem\u00f3ria RAM, 15 GB de VRAM com GPU dedicada e 78 GB de armazenamento, permite que todos os integrantes disponham do mesmo ambiente de processamento, evitando falhas inesperadas ou falta de componentes.</p>"},{"location":"etapas/entrega2/#conformidade-legal-e-etica","title":"Conformidade Legal e \u00c9tica","text":"<p>Este conjunto de dados, licenciado sob a descri\u00e7\u00e3o CC0 1.0, segue os padr\u00f5es de uma Licen\u00e7a de Dedica\u00e7\u00e3o ao Dom\u00ednio P\u00fablico, o que significa que os arquivos associados est\u00e3o dispon\u00edveis para uso p\u00fablico sem restri\u00e7\u00f5es de direitos autorais, permitindo copiar, modificar, distribuir e executar o trabalho, mesmo para fins comerciais, tudo sem pedir permiss\u00e3o. A defini\u00e7\u00e3o da licen\u00e7a do conjunto de dados pode ser encontrada na p\u00e1gina Data for: Identification of Plant Leaf Diseases Using a 9-layer Deep Convolutional Neural Network na sess\u00e3o \u201cLicense\u201d.</p>"},{"location":"etapas/entrega2/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<ul> <li>HUGHES, D. P.; SALATHE, M. An open access repository of images on plant health to enable the development of mobile disease diagnostics. arXiv, , 11 abr. 2016. Dispon\u00edvel em: http://arxiv.org/abs/1511.08060. Acesso em: 7 abr. 2024</li> <li>DataCamp. A Complete Guide to Data Augmentation. Learn about data augmentation techniques, applications, and tools with a TensorFlow and Keras tutorial. Novembro de 2022. Dispon\u00edvel em: https://www.datacamp.com/tutorial/complete-guide-data-augmentation. Acesso em: 7 abr. 2024.</li> </ul>"},{"location":"etapas/entrega3/","title":"An\u00e1lise explorat\u00f3ria dos dados","text":"<p>Durante esta fase, realizou-se uma an\u00e1lise das imagens de plantas presentes no conjunto de dados selecionado, associando cada imagem \u00e0 sua respectiva categoria indicada pela label (etiqueta).</p> <p>As labels, em ingl\u00eas, que distinguem os diversos tipos de plantas saud\u00e1veis e doentes est\u00e3o organizadas da seguinte maneira:  N\u00famero de identifica\u00e7\u00e3o - Esp\u00e9cie de planta - Tipo de Doen\u00e7a  Por exemplo: 3. Apple___healthy, onde o n\u00famero de identifica\u00e7\u00e3o \u00e9 3, a esp\u00e9cie de planta \u00e9 ma\u00e7\u00e3 e o tipo de doen\u00e7a \u00e9 saud\u00e1vel.</p> N\u00ba Esp\u00e9cie Tipo de Doen\u00e7a Label 0 Apple Apple_scab 0. Apple___Apple_scab 1 Apple Black_rot 1. Apple___Black_rot 2 Apple Cedar_apple_rust 2. Apple___Cedar_apple_rust 3 Apple healthy 3. Apple___healthy 4 Blueberry healthy 4. Blueberry___healthy 5 Cherry healthy 5. Cherry___healthy 6 Cherry Powdery_mildew 6. Cherry___Powdery_mildew 7 Corn Cercospora_leaf_spotGray_leaf_spot 7. Corn___Cercospora_leaf_spotGray_leaf_spot 8 Corn Common_rust 8. Corn___Common_rust 9 Corn healthy 9. Corn___health 10 Corn Northern_Leaf_Blight 10. Corn___Northern_Leaf_Blight 11 Grape Black_rot 11. Grape___Black_ro 12 Grape Esca(Black_Measles) 12. Grape___Esca(Black_Measles) 13 Grape healthy 13. Grape___healthy 14 Grape Leaf_blight(Isariopsis_Leaf_Spot) 14.Grape___Leaf_blight(Isariopsis_Leaf_Spot) 15 Orange Haunglongbing(Citrus_greening) 15.Orange___Haunglongbing(Citrus_greening) 16 Peach Bacterial_spot 16. Peach___Bacterial_spot 17 Peach healthy 17. Peach___healthy 18 Pepper,bell Bacterial_spot 18. Pepper,bell___Bacterial_spot 19 Pepper,bell healthy 19. Pepper,bell___healthy 20 Potato Early_blight 20. Potato___Early_blight 21 Potato healthy 21. Potato___healthy 22 Potato Late_blight 22. Potato___Late_blight 23 Raspberry healthy 23. Raspberry___healthy 24 Soybean healthy 24. Soybean___healthy 25 Squash Powdery_mildew 25. Squash___Powdery_mildew 26 Strawberry healthy 26. Strawberry___healthy 27 Strawberry Leaf_scorch 27. Strawberry___Leaf_scorch 28 Tomato Bacterial_spot 28. Tomato___Bacterial_spot 29 Tomato Early_blight 29. Tomato___Early_blight 30 Tomato healthy 30. Tomato___healthy 31 Tomato Late_blight 31. Tomato___Late_blight 32 Tomato Leaf_Mold 32. Tomato___Leaf_Mold 33 Tomato Septoria_leaf_spot 33. Tomato___Septoria_leaf_spot 34 Tomato Spider_mites Two-spotted_spider_mite 34. Tomato___Spider_mitesTwo-spotted_spider_mite 35 Tomato Target_Spot 35. Tomato___Target_Spot 36 Tomato Tomato_mosaic_virus 36. Tomato___Tomato_mosaic_virus 37 Tomato Tomato_Yellow_Leaf_Curl_Virus 37.Tomato___Tomato_Yellow_Leaf_Curl_Virus"},{"location":"etapas/entrega3/#dados-retornados-do-dataframe","title":"Dados retornados do dataframe","text":"<p>A estrutura total do dado retornado no data frame criado inclui as seguintes colunas:</p> <ul> <li>image: Esta coluna cont\u00e9m os dados das imagens representadas por matrizes tridimensionais.</li> <li>filename: Esta coluna cont\u00e9m os nomes dos arquivos das imagens, fornecendo informa\u00e7\u00f5es sobre a origem de cada imagem no conjunto de dados.</li> <li>label: Esta coluna cont\u00e9m os n\u00fameros das etiquetas associadas a cada imagem.</li> </ul> <p></p> <p></p> <p>O exemplo abaixo descreve uma imagem representada por uma matriz tridimensional, onde cada valor dentro da matriz representa a intensidade de cor de um pixel. A estrutura da matriz \u00e9 (244, 244, 3), onde:</p> <ul> <li> <p>O primeiro n\u00famero, 244, representa a altura da imagem, ou seja, quantos pixels a imagem tem na vertical.</p> </li> <li> <p>O segundo n\u00famero, tamb\u00e9m 244, indica a largura da imagem, ou seja, quantos pixels a imagem tem na horizontal.</p> </li> <li> <p>O terceiro n\u00famero, 3, denota a quantidade de canais de cores da imagem, indicando que a imagem est\u00e1 no formato RGB (Red, Green, Blue), com cada pixel representado por uma combina\u00e7\u00e3o de tr\u00eas valores num\u00e9ricos que correspondem \u00e0 intensidade de vermelho (R), verde (G) e azul (B)</p> </li> </ul> <p> </p> <p>A matriz mostrada \u00e9 um recorte da imagem, com valores num\u00e9ricos representando as intensidades de cor de cada pixel. Por exemplo, o primeiro pixel tem intensidades de [171, 161, 169] para os canais vermelho, verde e azul, respectivamente. Cada conjunto de valores [R, G, B] representa a cor do pixel na posi\u00e7\u00e3o correspondente da imagem.</p> <p>Al\u00e9m disso, a label associada a essa imagem \u00e9 35, servindo para categoriz\u00e1-la em um dos tipos de doen\u00e7as ou estado de sa\u00fade da planta, conforme o sistema de categoriza\u00e7\u00e3o estabelecido anteriormente. O exemplo a seguir \u00e9 uma imagem categorizada na label 35 (Tomato___Target_Spot):</p> <p> <p></p> <p></p>"},{"location":"etapas/entrega3/#executando-codigo","title":"Executando c\u00f3digo","text":"<p>Acesse o c\u00f3digo no Colab atrav\u00e9s do LINK e execute cada uma das c\u00e9lulas em ordem. O c\u00f3digo demonstra o que foi apresentado na subse\u00e7\u00e3o anterior, al\u00e9m de gerar um gr\u00e1fico relacionando a quantidade de labels com a quantidade de imagens de cada uma das labels.</p>"},{"location":"etapas/entrega3/#identificacao-de-padroes-e-correlacoes","title":"Identifica\u00e7\u00e3o de padr\u00f5es e correla\u00e7\u00f5es","text":"<p>Foi feito tamb\u00e9m um script no Colab LINK com a finalidade de obter estat\u00edsticas a partir de uma pequena amostra de dados. Esse script demonstra um gr\u00e1fico de quantas imagens tem para cada tipo de doen\u00e7a, al\u00e9m de mostrar exemplos de imagens para checar suas qualidades. </p> <p>O algoritmo de identifica\u00e7\u00e3o de padr\u00f5es aplicado ao dataset Plant_Village coletar\u00e1 caracter\u00edsticas visuais das imagens das plantas, incluindo padr\u00f5es de textura, forma, cor e estruturas espec\u00edficas associadas a doen\u00e7as ou condi\u00e7\u00f5es saud\u00e1veis. Essas caracter\u00edsticas ser\u00e3o extra\u00eddas atrav\u00e9s de camadas convolucionais em uma rede neural convolucional (CNN). Durante o treinamento, o algoritmo aprender\u00e1 a associar essas caracter\u00edsticas \u00e0s labels correspondentes, como diferentes doen\u00e7as de plantas ou condi\u00e7\u00f5es saud\u00e1veis. Assim, quando uma nova imagem de planta for fornecida como entrada, o algoritmo aplicar\u00e1 suascaracter\u00edsticas aprendidas para realizar a classifica\u00e7\u00e3o, determinando a doen\u00e7a ou condi\u00e7\u00e3o da planta com base nas semelhan\u00e7as com os exemplos de treinamento previamente rotulados.</p>"},{"location":"etapas/entrega4/","title":"Prepara\u00e7\u00e3o dos dados","text":""},{"location":"etapas/entrega4/#divisao-dos-conjuntos-de-dados","title":"Divis\u00e3o dos conjuntos de dados","text":"<p>Com a finalidade de alcan\u00e7ar uma melhor organiza\u00e7\u00e3o ao utilizar o modelo, foi realizada a divis\u00e3o de um conjunto de dados (ds) em conjuntos de treinamento, valida\u00e7\u00e3o e teste, como demonstrado na Imagem 1. Inicialmente, define-se que 80% dos dados ser\u00e3o destinados ao conjunto de treinamento. Em seguida, a vari\u00e1vel \u2018train_size\u2019 \u00e9 calculada como o n\u00famero inteiro do tamanho total do conjunto de dados multiplicado pela propor\u00e7\u00e3o destinada ao treinamento. Ap\u00f3s a defini\u00e7\u00e3o do tamanho do conjunto de treinamento, os dados s\u00e3o aleatoriamente embaralhados. O pr\u00f3ximo passo \u00e9 atribuir os dados de treinamento, utilizando o m\u00e9todo take, que seleciona os primeiros \u2018train_size\u2019 elementos do conjunto de dados embaralhados. Em seguida, os dados restantes ap\u00f3s o conjunto de treinamento s\u00e3o usados para formar o conjunto de teste. Esses dados s\u00e3o divididos ao meio, onde metade \u00e9 destinada ao conjunto de valida\u00e7\u00e3o e a outra metade ao conjunto de teste. Essa abordagem permite avaliar o desempenho do modelo em dados n\u00e3o vistos durante o treinamento, contribuindo para uma avalia\u00e7\u00e3o mais precisa da generaliza\u00e7\u00e3o do modelo.</p> <p> <p></p> <p>Imagem 1: Reparti\u00e7\u00e3o de treino, valida\u00e7\u00e3o e teste(Autor, 2024) </p> <p></p>"},{"location":"etapas/entrega4/#qualidade-da-limpeza-dos-dados","title":"Qualidade da limpeza dos dados","text":"<p>O conjunto de dados selecionado foi tratado com t\u00e9cnicas de data augmentation e j\u00e1 inclui imagens pr\u00e9-processadas e bem tratadas no que diz respeito \u00e0 dire\u00e7\u00e3o, ilumina\u00e7\u00e3o e clareza das imagens, n\u00e3o demandando um tratamento profundo (Imagem 2). Essas t\u00e9cnicas de augmentation contribuem para melhorar a capacidade do modelo de generalizar para novas imagens e garantir sua efic\u00e1cia em diferentes contextos e condi\u00e7\u00f5es.</p> <p> <p></p> <p>Imagem 2: Exemplos de imagens do Dataset (Autor, 2024) </p> <p></p> <p>Pelo alto custo de RAM que dificultaria o processamento dos moSdelos de Machine Learning e com o objetivo de simplificar o tratamento do banco de imagens, foi utilizado um cache de imagens, permitindo uma maior disponibilidade, al\u00e9m da randomiza\u00e7\u00e3o e pr\u00e9-carregamento dos dados (Imagem 3).</p> <p> <p></p> <p>Imagem 2: Cacheamento, randomiza\u00e7\u00e3o e pr\u00e9-carregamento dos dados (Autor, 2024) </p> <p></p>"},{"location":"etapas/entrega4/#normalizacao-e-padronizacao","title":"Normaliza\u00e7\u00e3o e padroniza\u00e7\u00e3o","text":"<p>A normaliza\u00e7\u00e3o de dados \u00e9 essencial no processamento de imagens e em outras tarefas de aprendizado de m\u00e1quina, pois ajusta a escala dos valores para um intervalo espec\u00edfico, geralmente entre 0 e 1. A normaliza\u00e7\u00e3o ajuda a evitar problemas de converg\u00eancia durante o treinamento, permitindo que os modelos aprendam de forma mais eficiente com os dados, uma vez que todas as caracter\u00edsticas estejam na mesma ordem de grandeza. No trecho de c\u00f3digo mostrado na Imagem 4, primeiramente, \u00e9 criado um modelo sequencial que ir\u00e1 aplicar uma s\u00e9rie de transforma\u00e7\u00f5es \u00e0s imagens. A primeira transforma\u00e7\u00e3o \u00e9 a \u201cResizing\u201d, que ajusta o tamanho das imagens para um tamanho padr\u00e3o definido pela vari\u00e1vel \u2018IMAGE_SIZE\u2019. Isso \u00e9 \u00fatil para garantir que todas as imagens tenham o mesmo tamanho, o que \u00e9 uma pr\u00e1tica comum em modelos de aprendizado profundo para garantir a compatibilidade de entrada. Em seguida, \u00e9 aplicada a transforma\u00e7\u00e3o de \u201cRescaling\u201d, que normaliza os valores dos pixels das imagens, dividindo cada valor de pixel pelo valor m\u00e1ximo poss\u00edvel (255 em imagens RGB). Isso comprime a escala de valores para o intervalo entre 0 e 1, o que \u00e9 prefer\u00edvel para o treinamento de redes neurais, pois facilita a converg\u00eancia e o aprendizado eficiente dos modelos.</p> <p> <p></p> <p>Imagem 3: Padroniza\u00e7\u00e3o dos dados (Autor, 2024) </p>"},{"location":"etapas/entrega4/#executando-o-codigo","title":"Executando o c\u00f3digo","text":"<p>O c\u00f3digo dispon\u00edvel no Colab, al\u00e9m de executar o que foi descrito nas se\u00e7\u00f5es anteriores com a classe de plantas tomate, tamb\u00e9m faz o mesmo processo com todas as classes de plantas mas com dados reduzidos. Esse fator \u00e9 apenas para fins de novas possibilidades de uso dos dados, mas a defini\u00e7\u00e3o do grupo at\u00e9 o momento \u00e9 utilizar apenas o tomate. Para executar o c\u00f3digo, acesse o Colab atrav\u00e9s do LINK e execute cada uma das c\u00e9lulas em ordem.</p>"},{"location":"etapas/entrega5/","title":"Sele\u00e7\u00e3o dos modelos com potencial","text":""},{"location":"etapas/entrega5/#remodelagem-dos-dados","title":"Remodelagem dos Dados","text":"<p>A fim de buscar melhor desempenho e por disponibilidade de RAM, os dados foram remodelados para metade dos pixels, agora com 128px. Al\u00e9m disso, os dados foram reduzidos em 50% da quantidade inicial, por\u00e9m, foi utilizado data augmentation de forma a gerar varia\u00e7\u00f5es das imagens em diferentes \u00e2ngulos para que n\u00e3o ocorresse uma perda t\u00e3o grande da qualidade do treinamento dada a redu\u00e7\u00e3o dos dados. E para otimiza\u00e7\u00e3o do processo de treinamento do modelo, foi buscado varia\u00e7\u00f5es dos lotes de imagens para reduzir o custo de hardware na execu\u00e7\u00e3o do treinamento.</p>"},{"location":"etapas/entrega5/#diversidade-e-adequacao-dos-modelos-testados","title":"Diversidade e Adequa\u00e7\u00e3o dos Modelos Testados","text":"<p>No que diz respeito \u00e0 diversidade e adequa\u00e7\u00e3o dos modelos testados, o c\u00f3digo apresenta uma abordagem abrangente. Ele come\u00e7a carregando e pr\u00e9-processando o conjunto de dados contendo as imagens de folhas de plantas com diferentes doen\u00e7as. Essa etapa \u00e9 crucial, pois fornece a base para o desenvolvimento e teste dos modelos de aprendizado de m\u00e1quina.</p> <p>A escolha de uma arquitetura de rede neural convolucional (CNN) no modelo \u00e9 justificada devido \u00e0 sua efic\u00e1cia comprovada em problemas de classifica\u00e7\u00e3o de imagens. A CNN \u00e9 uma escolha adequada para este problema, pois permite a extra\u00e7\u00e3o autom\u00e1tica de caracter\u00edsticas relevantes das imagens, como texturas e padr\u00f5es, que s\u00e3o importantes para distinguir diferentes doen\u00e7as nas folhas das plantas.</p> <p>Al\u00e9m disso, o c\u00f3digo incorpora t\u00e9cnicas de aumento de dados, como rota\u00e7\u00e3o e invers\u00e3o, para aumentar a diversidade do conjunto de dados. Isso \u00e9 importante para evitar overfitting e melhorar a capacidade do modelo de generalizar para novos dados. A Imagem 1 a seguir mostra o sum\u00e1rio e par\u00e2metros do modelo 1 que foi testado e selecionado como o mais adequado.</p> <p> <p></p> <p>Imagem 1: Sum\u00e1rio do modelo 1 (Autor, 2024) </p> <p></p> <p>Devido \u00e0s limita\u00e7\u00f5es da plataforma Google Colab e, tamb\u00e9m, de resultados provis\u00f3rios do treinamento de outras vers\u00f5es do modelo, a vers\u00e3o 1 do modelo foi a melhor otimizada e com as melhores m\u00e9tricas como resultado dos testes. Portanto, neste documento cont\u00e9m apenas os resultados gerados pelo treinamento da vers\u00e3o 1.</p> <p>Vale ressaltar que os outros modelos gerados estouraram o limite de uso da plataforma Google Colab durante seu treinamento, e geraram acur\u00e1cia geral abaixo da m\u00e9dia da vers\u00e3o, demonstrando assim que o modelo que melhor se adequa \u00e0s especifica\u00e7\u00f5es requisitadas.</p>"},{"location":"etapas/entrega5/#analise-critica-do-desempenho","title":"An\u00e1lise Cr\u00edtica do Desempenho","text":"<p>Quanto \u00e0 an\u00e1lise cr\u00edtica do desempenho, o c\u00f3digo fornece uma an\u00e1lise detalhada dos resultados obtidos durante o treinamento dos modelos. Ele monitora v\u00e1rias m\u00e9tricas de desempenho, como acur\u00e1cia, precis\u00e3o, recall, sensibilidade, especificidade, F1-score, entre outros, ao longo do tempo de treinamento. Essas m\u00e9tricas s\u00e3o fundamentais para avaliar o qu\u00e3o bem o modelo est\u00e1 performando em diferentes aspectos, como a capacidade de identificar corretamente as doen\u00e7as das folhas das plantas e evitar falsos positivos e falsos negativos.</p> <p>Al\u00e9m disso, o c\u00f3digo compara o desempenho de diferentes modelos, destacando suas vantagens e limita\u00e7\u00f5es. Isso \u00e9 feito analisando n\u00e3o apenas as m\u00e9tricas de desempenho final, mas tamb\u00e9m o hist\u00f3rico de m\u00e9tricas ao longo do treinamento. Essa compara\u00e7\u00e3o permite uma avalia\u00e7\u00e3o mais completa do desempenho de cada modelo e ajuda na identifica\u00e7\u00e3o dos modelos mais promissores para refinamento futuro.</p> <p> <p></p> <p>Imagem 2:  M\u00e9tricas de avalia\u00e7\u00e3o com 30 \u00e9pocas do modelo 1 (Autor, 2024)</p> <p></p> <p>A Imagem 2 acima mostra o relat\u00f3rio final com todas as m\u00e9tricas de avalia\u00e7\u00e3o. Durante o treinamento do modelo 1, foi observado que a melhor acur\u00e1cia final foi alcan\u00e7ada ap\u00f3s 30 epochs. Isso indica que, ap\u00f3s repetidas passagens pelos dados de treinamento e valida\u00e7\u00e3o, o modelo atingiu seu melhor desempenho de classifica\u00e7\u00e3o. Neste caso espec\u00edfico, 30 \u00e9pocas foram suficientes para treinar o modelo e obter sua melhor acur\u00e1cia e outras m\u00e9tricas. O tempo m\u00e9dio de treinamento foi de 1 hora  e 30 minutos.</p>"},{"location":"etapas/entrega5/#executando-o-codigo","title":"Executando o C\u00f3digo","text":"<p>Para executar o c\u00f3digo, acesse o Colab atrav\u00e9s do LINK e execute cada uma das c\u00e9lulas em ordem.</p>"},{"location":"etapas/entrega6/","title":"Otimiza\u00e7\u00e3o e ajuste fino do sistema","text":""},{"location":"etapas/entrega6/#otimizacao-de-hiperparametros","title":"Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros","text":"<p>\u00c9 clara a import\u00e2ncia de realizar testes utilizando o conceito da mudan\u00e7a de hiperpar\u00e2metros, uma vez que estes artefatos alteram de forma direta a estrutura do modelo podendo gerar diferentes resultados de m\u00e9tricas ao final dos testes.</p> <p>Durante o desenvolvimento do Mini Trabalho 5, o grupo realizou testes de otimiza\u00e7\u00e3o, na vers\u00e3o 1 do modelo, se aproveitando da mudan\u00e7a de hiperpar\u00e2metros. Focou-se, principalmente, na mudan\u00e7a do n\u00famero de \u201cEpochs\u201d e ap\u00f3s os resultados coletados, que ser\u00e3o exibidos nas imagens 1, 2, 3 e 4, concluiu-se que o n\u00famero ideal de epochs \u00e9 de 30 em um primeiro momento.</p> <p> <p></p> <p>Imagem 1: Resultado do treinamento utilizando 25 epochs (Autor, 2024)</p> <p></p> <p>Imagem 2: Resultado do treinamento utilizando 32 epochs (Autor, 2024)</p> <p></p> <p>Imagem 3: Resultado do treinamento utilizando 35 epochs (Autor, 2024)</p> <p></p> <p>Imagem 4: Resultado do treinamento utilizando 30 epochs (Autor, 2024)</p> <p></p>"},{"location":"etapas/entrega6/#validacao-cruzada","title":"Valida\u00e7\u00e3o Cruzada","text":"<p>O uso de t\u00e9cnicas de valida\u00e7\u00e3o cruzada \u00e9 essencial para avaliar o desempenho dos modelos de forma mais robusta e evitar o sobreajuste. No c\u00f3digo fornecido, a valida\u00e7\u00e3o cruzada \u00e9 implementada utilizando uma abordagem de divis\u00e3o dos dados em conjuntos de treinamento, valida\u00e7\u00e3o e teste.</p> <p>Al\u00e9m disso, o c\u00f3digo utiliza um m\u00e9todo similar ao \u201cKFold\u201d para dividir os dados em grupos e realizar o treinamento do modelo de forma iterativa, garantindo uma avalia\u00e7\u00e3o abrangente do desempenho do modelo em diferentes conjuntos de dados.</p>"},{"location":"etapas/entrega6/#melhoria-no-desempenho","title":"Melhoria no desempenho","text":"<p>Para demonstrar a efic\u00e1cia da otimiza\u00e7\u00e3o de hiperpar\u00e2metros, foram realizados experimentos de treinamento do modelo com diferentes configura\u00e7\u00f5es de hiperpar\u00e2metros. O principal hiperpar\u00e2metro alterado foi o n\u00famero de \u00e9pocas que o modelo processaria. O desempenho do modelo foi avaliado por meio de m\u00e9tricas de avalia\u00e7\u00e3o como acur\u00e1cia, precis\u00e3o, recall, F1-score, sensibilidade, especificidade, entre outras.</p> <p>Em adi\u00e7\u00e3o, no desenvolvimento deste Mini Trabalho, foi realizado a implementa\u00e7\u00e3o do um novo modelo, desta vez, utilizando Deep Learning, e foi posto o modelo para treinamento utilizando 30 epochs, onde obtivemos as seguintes m\u00e9tricas finais (Imagem 6), mostrando assim a evolu\u00e7\u00e3o do modelo em rela\u00e7\u00e3o \u00e0 vers\u00e3o 1 do Mini Trabalho 5 (Imagem 5).</p> <p> <p></p> <p>Imagem 5:   M\u00e9tricas obtidas no modelo V1 (Autor, 2024)</p> <p></p> <p>Imagem 6:   M\u00e9tricas obtidas no modelo V2 (Autor, 2024)</p> <p></p> <p>Al\u00e9m disso, no c\u00f3digo fornecido, foi realizada otimiza\u00e7\u00e3o utilizando o otimizador Adam com uma taxa de aprendizado de 0.001, beta_1 de 0.9, beta_2 de 0.999, epsilon de 0.1 e decaimento de 0.0, a fim de melhorar o desempenho do modelo. Junto a isso, s\u00e3o adotadas diversas t\u00e9cnicas, como aumento de dados, normaliza\u00e7\u00e3o, regulariza\u00e7\u00e3o, entre outras. Ap\u00f3s a implementa\u00e7\u00e3o dessas t\u00e9cnicas, otimiza\u00e7\u00f5es e ajustes dos hiperpar\u00e2metros, o tempo m\u00e9dio de treinamento passou de 1h30min (tempo m\u00e9dio apresentado no Mini Trabalho 5) para 30min (Imagem 7), tempo tr\u00eas vezes menor.</p> <p> <p></p> <p>Imagem 7:  M\u00e9tricas de avalia\u00e7\u00e3o com 30 \u00e9pocas do modelo 1 (Autor, 2024)</p> <p></p>"},{"location":"etapas/entrega6/#executando-codigo","title":"Executando C\u00f3digo","text":"<p>Para executar o c\u00f3digo, acesse o Colab atrav\u00e9s do LINK e execute cada uma das c\u00e9lulas em ordem.</p>"}]}